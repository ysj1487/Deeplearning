{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 리뷰 분류: 이진 분류 예제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
    "\n",
    "----\n",
    "\n",
    "2종 분류 또는 이진 분류는 아마도 가장 널리 적용된 머신 러닝 문제일 것입니다. 이 예제에서 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 법을 배우겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB 데이터셋\n",
    "\n",
    "인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용하겠습니다. 이 데이터셋은 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다.\n",
    "\n",
    "왜 훈련 데이터와 테스트 데이터를 나눌까요? 같은 데이터에서 머신 러닝 모델을 훈련하고 테스트해서는 절대 안 되기 때문입니다! 모델이 훈련 데이터에서 잘 작동한다는 것이 처음 만난 데이터에서도 잘 동작한다는 것을 보장하지 않습니다. 중요한 것은 새로운 데이터에 대한 모델의 성능입니다(사실 훈련 데이터의 레이블은 이미 알고 있기 때문에 이를 예측하는 모델은 필요하지 않습니다). 예를 들어 모델이 훈련 샘플과 타깃 사이의 매핑을 모두 외워버릴 수 있습니다. 이런 모델은 처음 만나는 데이터에서 타깃을 예측하는 작업에는 쓸모가 없습니다. 다음 장에서 이에 대해 더 자세히 살펴보겠습니다.\n",
    "\n",
    "MNIST 데이터셋처럼 IMDB 데이터셋도 케라스에 포함되어 있습니다. 이 데이터는 전처리되어 있어 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있습니다. 여기서 각 숫자는 사전에 있는 고유한 단어를 나타냅니다.\n",
    "\n",
    "다음 코드는 데이터셋을 로드합니다(처음 실행하면 17MB 정도의 데이터가 컴퓨터에 다운로드됩니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매개변수 `num_words=10000`은 훈련 데이터에서 가장 자주 나타나는 단어 10,000개만 사용하겠다는 의미입니다. 드물게 나타나는 단어는 무시하겠습니다. 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있습니다.\n",
    "\n",
    "변수 `train_data`와 `test_data`는 리뷰의 목록입니다. 각 리뷰는 단어 인덱스의 리스트입니다(단어 시퀀스가 인코딩된 것입니다). `train_labels`와 `test_labels`는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 자주 등장하는 단어 10,000개로 제한했기 때문에 단어 인덱스는 10,000을 넘지 않습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재미 삼아 이 리뷰 데이터 하나를 원래 영어 단어로 어떻게 바꾸는지 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
    "word_index = imdb.get_word_index()\n",
    "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# 리뷰를 디코딩합니다. \n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "신경망에 숫자 리스트를 주입할 수는 없습니다. 리스트를 텐서로 바꾸는 두 가지 방법이 있습니다:\n",
    "\n",
    "* 같은 길이가 되도록 리스트에 패딩을 추가하고 `(samples, sequence_length)` 크기의 정수 텐서로 변환합니다. 그다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용합니다(`Embedding` 층을 말하며 나중에 자세히 다루겠습니다).\n",
    "* 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환합니다. 예를 들면 시퀀스 `[3, 5]`를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10,000차원의 벡터로 각각 변환합니다. 그다음 부동 소수 벡터 데이터를 다룰 수 있는 `Dense` 층을 신경망의 첫 번째 층으로 사용합니다.\n",
    "\n",
    "여기서는 두 번째 방식을 사용하고 이해를 돕기 위해 직접 데이터를 원-핫 벡터로 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "\n",
    "# 훈련 데이터를 벡터로 변환합니다\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터를 벡터로 변환합니다\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 샘플은 다음과 같이 나타납니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블은 쉽게 벡터로 바꿀 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 벡터로 바꿉니다\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 신경망에 주입할 데이터가 준비되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 모델 만들기\n",
    "\n",
    "입력 데이터가 벡터이고 레이블은 스칼라(1 또는 0)입니다. 아마 앞으로 볼 수 있는 문제 중에서 가장 간단할 것입니다. 이런 문제에 잘 작동하는 네트워크 종류는 `relu` 활성화 함수를 사용한 완전 연결 층(즉, `Dense(16, activation='relu')`)을 그냥 쌓은 것입니다.\n",
    "\n",
    "`Dense` 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. 2장에서 `relu` 활성화 함수를 사용한 `Dense` 층을 다음과 같은 텐서 연산을 연결하여 구현하였습니다:\n",
    "\n",
    "`output = relu(dot(W, input) + b)`\n",
    "\n",
    "16개의 은닉 유닛이 있다는 것은 가중치 행렬 `W`의 크기가 `(input_dimension, 16)`이라는 뜻입니다. 입력 데이터와 `W`를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영됩니다(그리고 편향 벡터 `b`를 더하고 `relu` 연산을 적용합니다). 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있습니다. 은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있습니다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴입니다).\n",
    "\n",
    "`Dense` 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요합니다:\n",
    "\n",
    "* 얼마나 많은 층을 사용할 것인가\n",
    "* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가\n",
    "\n",
    "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배우겠습니다. 당분간은 저를 믿고 선택한 다음 구조를 따라 주세요.\n",
    "\n",
    "* 16개의 은닉 유닛을 가진 두 개의 은닉층\n",
    "* 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
    "\n",
    "중간에 있는 은닉층은 활성화 함수로 `relu`를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미합니다)을 출력하기 위해 시그모이드 활성화 함수를 사용합니다. `relu`는 음수를 0으로 만드는 함수입니다. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음이 이 신경망의 모습입니다:\n",
    "\n",
    "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 이 신경망의 케라스 구현입니다. 이전에 보았던 MNIST 예제와 비슷합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = \"relu\", input_shape = (10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 손실 함수와 옵티마이저를 선택해야 합니다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았습니다), `binary_crossentropy` 손실이 적합합니다. 이 함수가 유일한 선택은 아니고 예를 들어 `mean_squared_error`를 사용할 수도 있습니다. 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택입니다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정합니다. 여기에서는 원본 분포와 예측 분포 사이를 측정합니다.\n",
    "\n",
    "다음은 `rmsprop` 옵티마이저와 `binary_crossentropy` 손실 함수로 모델을 설정하는 단계입니다. 훈련하는 동안 정확도를 사용해 모니터링하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스에 `rmsprop`, `binary_crossentropy`, `accuracy`가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능합니다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있습니다. 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 `optimizer` 매개변수에 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "후자의 경우는 `loss`와 `metrics` 매개변수에 함수 객체를 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킵니다(`x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 20번 반복합니다). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것입니다. 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 7s 491us/step - loss: 0.4976 - acc: 0.7949 - val_loss: 0.3717 - val_acc: 0.8722\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 5s 361us/step - loss: 0.2957 - acc: 0.9043 - val_loss: 0.2989 - val_acc: 0.8907\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 5s 358us/step - loss: 0.2160 - acc: 0.9285 - val_loss: 0.3086 - val_acc: 0.8712\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 5s 354us/step - loss: 0.1742 - acc: 0.9435 - val_loss: 0.2831 - val_acc: 0.8840\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 5s 356us/step - loss: 0.1415 - acc: 0.9542 - val_loss: 0.2862 - val_acc: 0.8850\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 5s 349us/step - loss: 0.1143 - acc: 0.9654 - val_loss: 0.3078 - val_acc: 0.8815\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 5s 355us/step - loss: 0.0969 - acc: 0.9711 - val_loss: 0.3148 - val_acc: 0.8843\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 4s 270us/step - loss: 0.0803 - acc: 0.9765 - val_loss: 0.3867 - val_acc: 0.8658\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 4s 300us/step - loss: 0.0658 - acc: 0.9819 - val_loss: 0.3648 - val_acc: 0.8778\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 5s 353us/step - loss: 0.0553 - acc: 0.9850 - val_loss: 0.3863 - val_acc: 0.8791\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.0455 - acc: 0.9885 - val_loss: 0.4181 - val_acc: 0.8761\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 5s 338us/step - loss: 0.0386 - acc: 0.9914 - val_loss: 0.4521 - val_acc: 0.8699\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.0297 - acc: 0.9939 - val_loss: 0.4716 - val_acc: 0.8737\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 5s 343us/step - loss: 0.0244 - acc: 0.9949 - val_loss: 0.5025 - val_acc: 0.8717\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 5s 340us/step - loss: 0.0185 - acc: 0.9975 - val_loss: 0.5318 - val_acc: 0.8695\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 5s 327us/step - loss: 0.0155 - acc: 0.9982 - val_loss: 0.5714 - val_acc: 0.8692\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 5s 342us/step - loss: 0.0156 - acc: 0.9973 - val_loss: 0.6017 - val_acc: 0.8683\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 5s 325us/step - loss: 0.0087 - acc: 0.9993 - val_loss: 0.6876 - val_acc: 0.8628\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 5s 322us/step - loss: 0.0064 - acc: 0.9998 - val_loss: 0.7160 - val_acc: 0.8573\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 5s 337us/step - loss: 0.0098 - acc: 0.9979 - val_loss: 0.6983 - val_acc: 0.8661\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size = 512,\n",
    "                   validation_data = (x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU를 사용해도 에포크마다 2초가 걸리지 않습니다. 전체 훈련은 20초 이상 걸립니다. 에포크가 끝날 때마다 10,000개의 검증 샘플 데이터에서 손실과 정확도를 계산하기 때문에 약간씩 지연됩니다.\n",
    "\n",
    "`model.fit()` 메서드는 `History` 객체를 반환합니다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 `history` 속성을 가지고 있습니다. 한 번 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 딕셔너리는 훈련과 검증하는 동안 모니터링할 측정 지표당 하나씩 모두 네 개의 항목을 담고 있습니다. 맷플롯립을 사용해 훈련과 검증 데이터에 대한 손실과 정확도를 그려 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# ‘b’는 파란색 실선을 의미합니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도입니다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다를 수 있습니다.\n",
    "\n",
    "여기에서 볼 수 있듯이 훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가합니다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다. 검증 손실과 정확도는 이와 같지 않습니다. 4번째 에포크에서 그래프가 역전되는 것 같습니다. 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례입니다. 정확한 용어로 말하면 과대적합되었다고 합니다. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못합니다.\n",
    "\n",
    "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지할 수 있습니다. 일반적으로 4장에서 보게 될 과대적합을 완화하는 다양한 종류의 기술을 사용할 수 있습니다.\n",
    "\n",
    "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 6s 246us/step - loss: 0.4748 - acc: 0.8209\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 4s 168us/step - loss: 0.2675 - acc: 0.9098\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.2005 - acc: 0.9284\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 5s 217us/step - loss: 0.1682 - acc: 0.9392\n",
      "25000/25000 [==============================] - 6s 241us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32114709000587466, 0.87416]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아주 단순한 방식으로도 87%의 정확도를 달성했습니다. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델을 훈련시킨 후에 이를 실전 환경에서 사용하고 싶을 것입니다. `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14019379],\n",
       "       [0.9997268 ],\n",
       "       [0.32121867],\n",
       "       ...,\n",
       "       [0.07601225],\n",
       "       [0.04168651],\n",
       "       [0.469966  ]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서처럼 이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족합니다(0.6, 0.4). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다:\n",
    "\n",
    "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요합니다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있습니다.\n",
    "* `relu` 활성화 함수와 함께 `Dense` 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 될 것입니다.\n",
    "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 `sigmoid` 활성화 함수를 가진 `Dense` 층으로 끝나야 합니다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값입니다.\n",
    "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 `binary_crossentropy`입니다.\n",
    "* `rmsprop` 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택입니다. 걱정할 거리가 하나 줄은 셈입니다.\n",
    "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 됩니다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = str(\"it wasn't impressed it's just the contents were not delivered accurately\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'was', \"n't\", 'impressed', 'it', \"'s\", 'just', 'the', 'contents', 'were', 'not', 'delivered', 'accurately']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from keras.preprocessing import sequence\n",
    "tokens = word_tokenize(test_review)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 13, 1552, 9, 3576, 40, 1, 68, 21, 2129, 5932]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in tokens:\n",
    "    idx = word_index.get(i)\n",
    "    if idx != None and idx < 10000:\n",
    "        result.append(word_index.get(i))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = vectorize_sequences([result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46982974]]\n",
      "부정리뷰\n"
     ]
    }
   ],
   "source": [
    "predict_result = model.predict(test_X)\n",
    "print(predict_result)\n",
    "if predict_result > 0.5:\n",
    "    print(\"긍정리뷰\")\n",
    "else:\n",
    "    print(\"부정리뷰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46982974]]\n",
      "부정리뷰\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from keras.preprocessing import sequence\n",
    "test=[]\n",
    "word2index = imdb.get_word_index()\n",
    "for word in word_tokenize(test_review):\n",
    "     test.append(word2index[word])\n",
    "\n",
    "test=sequence.pad_sequences([test], maxlen=10000)\n",
    "model.predict(test)\n",
    "print(predict_result)\n",
    "if predict_result > 0.5:\n",
    "    print(\"긍정리뷰\")\n",
    "else:\n",
    "    print(\"부정리뷰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
